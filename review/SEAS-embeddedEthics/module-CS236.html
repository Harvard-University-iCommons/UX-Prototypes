<!DOCTYPE html>
<html lang="en">

  <head>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-131338240-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-131338240-1');
    </script>

    <meta name="description"
          content="Embedded EthiCS @ Harvard integrates ethical reasoning into core Computer Science courses. It teaches students to think through the ethical and social implications of the systems, programs, and algorithms they design and develop.">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <!-- Favicons -->
    <link href="img/favicon.png" rel="icon">
    <link href="img/apple-touch-icon.png" rel="apple-touch-icon">

    <title>Course Modules | CS 236 | Embedded EthiCS @ Harvard</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Icon library at https://fontawesome.com/icons -->
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.2/css/all.css" integrity="sha384-/rXc/GQVaYpyDdyxK+ecHPVYJSN9bmVFBvjA/9eOB+pb3F2w2N6fc5qB9Ew5yIns" crossorigin="anonymous">

    <!-- Custom fonts for this template -->
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Kaushan+Script' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700' rel='stylesheet' type='text/css'>

    <!-- Custom styles for this template -->
    <link href="css/agency.min.css" rel="stylesheet">

    <style>
      a.moreInfo:link, a.moreInfo:visited {
          color: #AB4E03;
          text-decoration: none;
          background-color: transparent;
          -webkit-text-decoration-skip: objects;
          font-size: 1.05em;
      }

      section h3.section-subheading {
      font-size: 1.5em;
      font-weight: 400;
      font-style: normal;
      margin-bottom: 75px;
      text-transform: none;
      font-family: arial;
      }

      .copyright {
      color: #999;
      }

      .navbar-nav {
      font-family: Montserrat,-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,'Helvetica Neue',Arial,sans-serif,'Apple Color Emoji','Segoe UI Emoji','Segoe UI Symbol','Noto Color Emoji';
      font-size: 90%;
      font-weight: 400;
      }

      .navbar-dark .navbar-nav .nav-link {
      color: #fff;
      }

      a.nav-link {
      color: #fff;
      padding: 1.1em 1em!important;
      }

    </style>

  </head>

  <body id="page-top">

    <!-- Navbar -->
    <nav class="navbar fixed-top navbar-expand-lg navbar-dark bg-dark">

      <a class="navbar-brand">
        <img src="img/harvard-logo.png" alt="Harvard University logo" width="200">
      </a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>

      <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav ml-auto text-uppercase">
          <li class="nav-item">
            <a class="nav-link" href="index.html">Home</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="about.html">About</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="team.html">Team</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="module.html" style="color: #fed136;">Course Modules</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="news.html">
              News
            </a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="publications.html">Publications</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="contact.html">Contact us</a>
          </li>
        </ul>
      </div>

    </nav>

    <h1 hidden>
      Embedded ethics at Harvard: Harvard: bringing ethical reasoning into the computer science curriculum.
    </h1>

    <!-- Header -->
    <header class="masthead">
      <div class="container">
        <div class="row">
          <div class="col-md-12">
            <div style=" margin-top: 6em; padding: 1em; background: none repeat scroll 0 0 rgba(108, 109, 110, 0);">
              <div class="intro-lead-in" style="line-height: 1.5em; font-family:verdana,arial,sans-serif; font-style: normal; color: #fff; font-size: 1.3em;">
                <span style="color: #FFDB6D; font-weight: 400;">
                  Embedded EthiCS
                </span>
                <span style="font-size: smaller;">@</span>
                Harvard: bringing ethical reasoning into the computer science curriculum.
              </div>
            </div>
          </div>
        </div>
      </div>
    </header>

    <div class="container" style="margin-top: 2em;">
        <div class="row">
          <div class="col-md-12">
            <a href="module.html" class="moreInfo">Course Modules</a>
            / CS 236: Topics at the Interface of Economics and Computer Science 
          </div>
        </div>
    </div>

    <section id="module">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center" style="margin-top: -5em;">
            <h2 class="section-heading" style="font-size: 2em;">Repository of Open Source Course Modules</h2>
          </div>
        </div>

        <div class="row" style="margin-top: 4em;">
          <div class="col-md-12">
            <ul class="nav nav-tabs justify-content-center" id="myTab" role="tablist">
              <li class="nav-item">
                <a class="nav-link active moreInfo" id="home-tab" data-toggle="tab" href="#overview" role="tab" aria-controls="home" aria-selected="true">
                  Overview
                </a>
              </li>
              <li class="nav-item">
                <a class="nav-link moreInfo" id="goal-tab" data-toggle="tab" href="#goal" role="tab" aria-controls="goal" aria-selected="false">
                  Goals
                </a>
              </li>
              <li class="nav-item">
                <a class="nav-link moreInfo" id="material-tab" data-toggle="tab" href="#material" role="tab" aria-controls="material" aria-selected="false">
                  Materials
                </a>
              </li>
              <li class="nav-item">
                <a class="nav-link moreInfo" id="implementation-tab" data-toggle="tab" href="#implementation" role="tab" aria-controls="implementation" aria-selected="false">
                  Implementation
                </a>
              </li>
            </ul>
            <div class="tab-content" id="myTabContent">

              <div class="tab-pane fade show active" id="overview" role="tabpanel" aria-labelledby="home-tab">

                <div class="row">
                  <div class="col">
                    &nbsp;
                  </div>
                </div>

                <div class="row">
                  <div class="col-8">
                    <p>
                      <strong>
                        Course:
                      </strong>
                      CS 236: Topics at the Interface of Economics and Computer Science 
                    </p>
                    <p>
                      <strong>
                        Course Level:
                      </strong>
                      Graduate
                    </p>
                    <p>
                      <strong>
                        Course Description:
                      </strong>
                    "This is a rotating topics course that studies the interplay between computation and economics. Topics covered include
                    but are not limited to electronic commerce, computational social choice, computational mechanism design, peer
                    production, prediction markets and reputation systems. The class is seminar style and readings are drawn from artificial
                    intelligence, theoretical computer science, multi-agent systems, economic theory, and operations research."
                    </p>
                  </div>
                  <div class="col-4">
                  </div>
                </div>

                <div class="row">
                  <div class="col">
                    <hr>
                  </div>
                </div>

                <div class="row">
                  <div class="col-8">
                    <p>
                      <strong>
                        Module Topic:
                      </strong>
                      Interpretability and Explanation 
                    </p>
                    <p>
                      <strong>
                        Module Author:
                      </strong>
                      Kate Vredenburgh
                    </p>
                    <p>
                      <strong>
                        Semesters Taught:
                      </strong>
                      Spring 2017-2018
                    </p>
                    <p>
                      <strong>
                        Tags:
                      </strong>
                    </p>
                    <dl>
                        <dd>
                            interpretability <span class="badge badge-success">both</span>
                        </dd>
                        <dd>
                            explainability <span class="badge badge-success">both</span>
                        </dd>
                        <dd>
                            algorithms <span class="badge badge-primary">CS</span>
                        </dd>
                        <dd>
                            opacity <span class="badge badge-primary">CS</span>
                        </dd>
                        <dd>
                            explanation <span class="badge badge-warning">phil</span>
                        </dd>
                        <dd>
                            reasons <span class="badge badge-warning">phil</span>
                        </dd>
                        <dd>
                            rights <span class="badge badge-warning">phil</span>
                        </dd>
                        <dd>
                            obligation <span class="badge badge-warning">phil</span>
                        </dd>
                    </dl>
                    <p>
                      <strong>
                        Module Overview:
                      </strong>
                      In this module, we consider the ethics of interpretability. GDPR’s Article 15, 2f requirement that individuals be provided “meaningful information” about the logic of automated decisions. Legal scholars, politicians, and journalists have read GDPR as establishing a right to explanation, although not without pushback.
                    </p>
                    <p>
                        The module considers whether decision-makers ought to be required provide explanations of automated decisions, and, if so, what sort of explanations those should be. It first examines different reasons why one might say that that algorithms are not explainable. It then asks what underlying purpose explanation serves, such that there may be a right to explanation.
                    </p>
                  </div>
                  <div class="col-4">
                  </div>
                </div>

                <div class="row">
                  <div class="col">
                    <hr>
                  </div>
                </div>

                <div class="row">
                  <div class="col-8">
                    <p>
                      <strong>
                        Connection to Course Technical Material:
                      </strong>
                      Two weeks of the course deal with interpretability. This module follows up directly on those weeks, asking why interpretability matters, whether it should be required, and whether the concept of interpretability is the same concept as explainability.
                    </p>
                  </div>
                  <div class="col-4">
                    <p class="text-muted small">
                      
                    </p>
                  </div>
                </div>

                <div class="row">
                  <div class="col">
                    <hr>
                  </div>
                </div>

              </div>

              <div class="tab-pane fade" id="goal" role="tabpanel" aria-labelledby="goal-tab">

                <div class="row">
                  <div class="col">
                    &nbsp;
                  </div>
                </div>

                <div class="row">
                  <div class="col-8">
                    <p>
                      <strong>
                        Module Goals:
                      </strong>
                    </p>
                    <ul>
                        <li>
                            Isolate properties of algorithms that make them opaque, or difficult to interpret or understand. 
                        </li>
                        <li>
                            Introduce students to different concepts of explainability, and how those concepts relate to interpretability. 
                        </li>
                        <li>
                            Discuss why explanations of algorithmic decisions are important. 
                        </li>
                        <li>
                            Brainstorm and examine technical and non-technical solutions to the problem of opacity.  
                        </li>
                    </ul>
                  </div>
                  <div class="col-4"></div>
                </div>

                <div class="row">
                  <div class="col">
                    <hr>
                  </div>
                </div>

                <div class="row">
                  <div class="col-8">
                    <p>
                      <strong>
                        Key Philosophical Questions:
                      </strong>
                    </p>
                    <ol>
                        <li>
                            When and why are algorithms opaque? 
                        </li>
                        <li>
                            What is the interest that could underly a right to explanation? 
                        </li>
                        <li>
                            What are technical and non-technical solutions to the problem of opacity in the form of specific rights protections? 
                        </li>
                    </ol>
                  </div>
                  <div class="col-4">
                    <p class="text-muted small">

                    </p>
                  </div>
                </div>

              </div>

              <div class="tab-pane fade" id="material" role="tabpanel" aria-labelledby="material-tab">

                <div class="row">
                  <div class="col">
                    &nbsp;
                  </div>
                </div>

                <div class="row">
                  <div class="col-8">
                    <ul>
                        <li>
                            Barocas and Selbst (2018), “The Intuitive Appeal of Explainable Machines.”
                        </li>
                    </ul>
                    <p>
                      <strong>
                        Key Philosophical Concepts:
                      </strong>
                    </p>
                    <ul>
                        <li>
                            Reasons
                        </li>
                        <li>
                            Explanation
                        </li>
                        <li>
                            Interest-based accounts of rights 
                        </li>
                        <li>
                            Obligation 
                        </li>
                    </ul>
                  </div>
                  <div class="col-4">
                    <p class="text-muted small">
                        This article distinguishes two different ways in which algorithms can be opaque: inscrutability, and non-intuitiveness. This distinction sets up the lecture’s discussion of what kinds of explanations decision-makers should be required to give of algorithmic decisions (if any), and whether it is technically feasible for them to provide these explanations. The article also argues for a particular solution to the problem of opacity, algorithmic impact statements, which are a very useful foil to the activity and discussion that ask students to brainstorm solutions. 
                    </p>
                  </div>
                </div>

              </div>

              <div class="tab-pane fade" id="implementation" role="tabpanel" aria-labelledby="implementation-tab">

                <div class="row">
                  <div class="col">
                    &nbsp;
                  </div>
                </div>

                <div class="row">
                  <div class="col-8">
                    <p>
                      <strong>
                        Class Agenda:
                      </strong>
                    </p>
                    <ol>
                        <li>
                            An introduction to the problem of explainability: why is it important that algorithms are explainable? 
                        </li>
                        <li>
                            Discussion of why some algorithms are not interpretable, i.e., are difficult or impossible to understand. 
                        </li>
                        <li>
                            Discussion of what features of decisions in certain institutions give rise to a need for explanation: the exercise of power and distributed knowledge. 
                        </li>
                        <li>
                            Examine whether individuals are owed explanations directly, as a matter of respect, or whether individuals need explanations to be able to contest decisions, adjust their behavior to the rules, use their voice to influence institutions, etc. 
                        </li>
                        <li>
                            Brainstorming and discussion of technical and non-technical solutions, taking inspiration from Barocas and Selbst. 
                        </li>
                    </ol>
                  </div>
                  <div class="col-4">
                    <p class="text-muted small">
                    </p>
                  </div>
                </div>

                <div class="row">
                  <div class="col">
                    <hr>
                  </div>
                </div>

                <div class="row">
                  <div class="col-8">
                    <ul>
                        <strong>
                            Sample Class Activity:
                        </strong>
                        <p>
                            Students are broken up into small groups and given short descriptions of real-world cases where an institution used an opaque decision-making algorithm. (Different groups receive different cases.) Groups are asked to: (1) identify what kind of explanation seemed to be required; and (2) brainstorm one technical and one non-technical solution that would enable decision-makers to give such explanations. The Embedded EthiCS fellow then leads a class-wide debrief, helping students to identify common themes in the groups’ answers. 
                        </p>
                    </p>
                  </div>
                  <div class="col-4">
                    <p class="text-muted small">

                    </p>
                  </div>
                </div>

                <div class="row">
                  <div class="col">
                    <hr>
                  </div>
                </div>

              </div>

            </div>
          </div>
        </div>
      </div>
    </section>

    <div class="container">
      <div class="row">
      </div>
    </div>

    <!-- Footer -->
    <footer>
      <div class="container-fluid">
        <div class="row">
          <nav class="navbar navbar-dark bg-dark" style="width: 100%; margin-bottom: -1.75em;">
            <!-- Navbar content -->
            <div class="col-md-2 col-lg-1">
              <a class="navbar-brand" rel="license" href="http://creativecommons.org/licenses/by/4.0/" target="_blank">
                <img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" />
              </a>
            </div>
            <div class="col-md-10 col-lg-11">
              <div class="copyright mr-auto">
                <span style="color: #A6A6A6">Except where otherwise noted, content on this site is licensed under a </span>
                <a rel="license" href="http://creativecommons.org/licenses/by/4.0/" target="_blank">Creative Commons Attribution 4.0 International License</a>.
                |
                <a href="https://accessibility.huit.harvard.edu/digital-accessibility-policy">Accessibility</a>
              </div>
            </div>
          </nav>
        </div>
      </div>
    </footer>

    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

    <!-- Contact form JavaScript -->
    <script src="js/jqBootstrapValidation.js"></script>
    <script src="js/contact_me.js"></script>

    <!-- Custom scripts for this template -->
    <script src="js/agency.min.js"></script>

  </body>

</html>
