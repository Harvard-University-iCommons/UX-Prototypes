<!DOCTYPE html>
<html lang="en">

  <head>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-131338240-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-131338240-1');
    </script>

    <meta name="description"
          content="Embedded EthiCS @ Harvard integrates ethical reasoning into core Computer Science courses. It teaches students to think through the ethical and social implications of the systems, programs, and algorithms they design and develop.">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <!-- Favicons -->
    <link href="img/favicon.png" rel="icon">
    <link href="img/apple-touch-icon.png" rel="apple-touch-icon">

    <title>Course Modules | CS 287 | Embedded EthiCS @ Harvard</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Icon library at https://fontawesome.com/icons -->
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.2/css/all.css" integrity="sha384-/rXc/GQVaYpyDdyxK+ecHPVYJSN9bmVFBvjA/9eOB+pb3F2w2N6fc5qB9Ew5yIns" crossorigin="anonymous">

    <!-- Custom fonts for this template -->
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Kaushan+Script' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700' rel='stylesheet' type='text/css'>

    <!-- Custom styles for this template -->
    <link href="css/agency.min.css" rel="stylesheet">

    <style>
      a.moreInfo:link, a.moreInfo:visited {
          color: #AB4E03;
          text-decoration: none;
          background-color: transparent;
          -webkit-text-decoration-skip: objects;
          font-size: 1.05em;
      }

      section h3.section-subheading {
      font-size: 1.5em;
      font-weight: 400;
      font-style: normal;
      margin-bottom: 75px;
      text-transform: none;
      font-family: arial;
      }

      .copyright {
      color: #999;
      }

      .navbar-nav {
      font-family: Montserrat,-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,'Helvetica Neue',Arial,sans-serif,'Apple Color Emoji','Segoe UI Emoji','Segoe UI Symbol','Noto Color Emoji';
      font-size: 90%;
      font-weight: 400;
      }

      .navbar-dark .navbar-nav .nav-link {
      color: #fff;
      }

      a.nav-link {
      color: #fff;
      padding: 1.1em 1em!important;
      }

    </style>

  </head>

  <body id="page-top">

    <!-- Navbar -->
    <nav class="navbar fixed-top navbar-expand-lg navbar-dark bg-dark">

      <a class="navbar-brand">
        <img src="img/harvard-logo.png" alt="Harvard University logo" width="200">
      </a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>

      <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav ml-auto text-uppercase">
          <li class="nav-item">
            <a class="nav-link" href="index.html">Home</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="about.html">About</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="team.html">Team</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="module.html" style="color: #fed136;">Course Modules</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="news.html">
              News
            </a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="publications.html">Publications</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="contact.html">Contact us</a>
          </li>
        </ul>
      </div>

    </nav>

    <h1 hidden>
      Embedded ethics at Harvard: Harvard: bringing ethical reasoning into the computer science curriculum.
    </h1>

    <!-- Header -->
    <header class="masthead">
      <div class="container">
        <div class="row">
          <div class="col-md-12">
            <div style=" margin-top: 6em; padding: 1em; background: none repeat scroll 0 0 rgba(108, 109, 110, 0);">
              <div class="intro-lead-in" style="line-height: 1.5em; font-family:verdana,arial,sans-serif; font-style: normal; color: #fff; font-size: 1.3em;">
                <span style="color: #FFDB6D; font-weight: 400;">
                  Embedded EthiCS
                </span>
                <span style="font-size: smaller;">@</span>
                Harvard: bringing ethical reasoning into the computer science curriculum.
              </div>
            </div>
          </div>
        </div>
      </div>
    </header>

    <div class="container" style="margin-top: 2em;">
        <div class="row">
          <div class="col-md-12">
            <a href="module.html" class="moreInfo">Course Modules</a>
            / CS 287: Natural Language Processing
          </div>
        </div>
    </div>

    <section id="module">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center" style="margin-top: -5em;">
            <h2 class="section-heading" style="font-size: 2em;">Repository of Open Source Course Modules</h2>
          </div>
        </div>

        <div class="row" style="margin-top: 4em;">
          <div class="col-md-12">
            <!-- Tabs -->
            <ul class="nav nav-tabs justify-content-center" id="myTab" role="tablist">
              <li class="nav-item">
                <a class="nav-link active moreInfo" id="home-tab" data-toggle="tab" href="#overview" role="tab" aria-controls="home" aria-selected="true">
                  Overview
                </a>
              </li>
              <li class="nav-item">
                <a class="nav-link moreInfo" id="goal-tab" data-toggle="tab" href="#goal" role="tab" aria-controls="goal" aria-selected="false">
                  Goals
                </a>
              </li>
              <li class="nav-item">
                <a class="nav-link moreInfo" id="material-tab" data-toggle="tab" href="#material" role="tab" aria-controls="material" aria-selected="false">
                  Materials
                </a>
              </li>
              <li class="nav-item">
                <a class="nav-link moreInfo" id="implementation-tab" data-toggle="tab" href="#implementation" role="tab" aria-controls="implementation" aria-selected="false">
                  Implementation
                </a>
              </li>
            </ul>
            <div class="tab-content" id="myTabContent">

                <!-- Content for Overview tab -->
                <div class="tab-pane fade show active" id="overview" role="tabpanel" aria-labelledby="home-tab">

                    <div class="row">
                        <div class="col">
                            &nbsp;
                        </div>
                        </div>

                        <div class="row">
                        <div class="col-8">
                            <p>
                                <strong>
                                    Course:
                                </strong>
                                CS 287: Natural Language Processing
                            </p>
                            <p>
                                <strong>
                                    Course Level:
                                </strong>
                                Graduate
                            </p>
                            <p>
                                <strong>
                                    Course Description:
                                </strong>
                                "Machine learning for natural language processing with a focus on deep learning and generative models. Topics include language modeling, information extraction, multi-model applications, text generation, machine translation, and deep generative models. Course is taught as a reading seminar with student presentations."                                
                            </p>
                            <p>
                                (<a href="https://harvard-ml-courses.github.io/cs287-web/" target="_blank" class="moreInfo">Course description
                                <sup><i class="fas fa-external-link-alt fa-sm"></i></sup></a>)"
                            </p>
                        </div>
                        <div class="col-4">
                        </div>
                    </div>

                    <div class="row">
                        <div class="col">
                            <hr>
                        </div>
                    </div>

                    <div class="row">
                        <div class="col-8">
                            <p>
                            <strong>
                                Module Topic:
                            </strong>
                            Bias and Stereotypes in Word-Embedding software
                            </p>
                            <p>
                            <strong>
                                Module Author:
                            </strong>
                            Diana Acosta-Navas
                            </p>
                            <p>
                            <strong>
                                Semesters Taught:
                            </strong>
                            Spring 2019
                            </p>
                            <p>
                            <strong>
                                Tags:
                            </strong>
                            </p>
                            <dl>
                                <dd>
                                    bias <span class="badge badge-warning">phil</span>
                                </dd>
                                <dd>
                                    stereotypes <span class="badge badge-warning">phil</span>
                                </dd>
                                <dd>
                                    discrimination <span class="badge badge-warning">phil</span>
                                </dd>
                                <dd>
                                    natural language processing <span class="badge badge-primary">CS</span>
                                </dd>
                                <dd>
                                    word embeddings <span class="badge badge-primary">CS</span>
                                </dd>
                                <dd>
                                    machine learning <span class="badge badge-primary">CS</span>
                                </dd>

                                <!-- Templates for tags
                                <dd>
                                    phil <span class="badge badge-warning">phil</span>
                                </dd>
                                <dd>
                                    cs <span class="badge badge-primary">CS</span>
                                </dd>
                                <dd>
                                    both <span class="badge badge-success">both</span>
                                </dd> -->
                            </dl>
                            <div class="col-4">
                            </div>
                        </div>
    
                        <div class="row">
                            <div class="col-8">
                                <p>
                                <strong>
                                    Module Overview:
                                </strong>
                                </p>
                                <p>
                                    The module examines the relation between gender stereotypes and the biases encoded in word embeddings. Students discuss some of the ethical problems that arise when gender bias becomes encoded in word embeddings, including the perpetuation and amplification of stereotypes, the infliction of representational and allocative harm, and the solidification of prejudice. After discussing some pros and cons of debiasing algorithms, the final part of the module explores the moral concerns that this solution may raise. This final discussion focuses on the thought that bias often happens without our full awareness, hence debiasing and other technical solutions should be immersed in wide-ranging cultural transformations towards inclusion and equality.
                                </p>
                            </div>
                            <div class="col-4">
                                <p class="text-muted small">
                                    
                                </p>
                            </div>
                        </div>
                    </div>

                    <div class="row">
                        <div class="col">
                            <hr>
                        </div>
                    </div>

                    <div class="row">
                        <div class="col-8">
                            <p>
                            <strong>
                                Connection to Course Material:
                            </strong>
                            In the lead-up to the module, the course covers word-embedding techniques and their potential uses in processing natural language. In the module we examine a potential drawback of these techniques and the ethical problems raised by their employment, while also examining the advantages and disadvantages of alternative approaches. Specifically, the module invites students to weigh the technical advantages of word-embeddings against their potential to propagate gender stereotypes by encoding biases rooted in our use of language. Students are provided with philosophical concepts that help them articulate whether taking advantage of the computing power offered by word embeddings justifies the kind of harm that may be inflicted when biases are perpetuated and solidified.
                            </p>
                        </div>
                        <div class="col-4">
                            <p class="text-muted small">
                                
                            </p>
                        </div>
                    </div>

                </div>

                <!-- Content for Goals tab -->
                <div class="tab-pane fade" id="goal" role="tabpanel" aria-labelledby="goal-tab">

                    <div class="row">
                    <div class="col">
                        &nbsp;
                    </div>
                    </div>

                    <div class="row">
                        <div class="col-8">
                            <p>
                            <strong>
                                Module Goals:
                            </strong>
                            </p>
                            <ol>
                                <li>
                                    Introducing students to the concepts of bias, stereotypes, and discrimination.
                                </li>
                                <li>
                                    Discussing the existence of gender biases in word-embedding software, and its correlation to gender stereotypes.
                                </li>
                                <li>
                                    Guiding students in thinking about the ethical problems raised by the presence of gender bias in word-embedding software.
                                </li>
                                <li>
                                    Prompting students to consider the potential advantages of debiasing word-embeddings, and its potential drawbacks.
                                </li>
                                <li>
                                    Using case-studies to train students to identify morally problematic aspects in the context of complex real-world scenarios.
                                </li>
                            </ol>
                        </div>
                        <div class="col-4">
                            <p class="text-muted small">
                                
                            </p>
                        </div>
                    </div>

                    <div class="row">
                    <div class="col">
                        <hr>
                    </div>
                    </div>

                    <div class="row">
                    <div class="col-8">
                        <p>
                        <strong>
                            Key Philosophical Questions:
                        </strong>
                        </p>
                        <ol>
                            <li>
                                What are the distinctive features of stereotypes?
                            </li>
                            <li>
                                What makes stereotypes morally problematic?
                            </li>
                            <li>
                                Can individuals be harmed by the presence of stereotypes in language processing software?
                            </li>
                            <li>
                                Can debiasing algorithms resolve the issue given that bias and stereotypes are widespread in our culture?
                            </li>
                        </ol>
                    </div>
                    <div class="col-4">
                        <p class="text-muted small">
                            
                        </p>
                    </div>
                    </div>

                </div>

                <!-- Content for Material tab -->
                <div class="tab-pane fade" id="material" role="tabpanel" aria-labelledby="material-tab">

                    <div class="row">
                    <div class="col">
                        &nbsp;
                    </div>
                    </div>

                    <div class="row">
                        <div class="col-8">
                            <p>
                            <strong>
                                Key Philosophical Concepts:
                            </strong>
                            </p>
                            <ul>
                                <li>
                                    Bias (explicit vs. implicit)
                                </li>
                                <li>
                                    Stereotypes
                                </li>
                                <li>
                                    Discrimination
                                </li>
                                <li>
                                    Statistical truths vs essentialist claims
                                </li>
                                <li>
                                    Prejudice
                                </li>
                                <li>
                                    Representational vs. allocative harms
                                </li>
                            </ul>
                        </div>
                        <div class="col-4">
                            <p class="text-muted small">

                            </p>
                        </div>
                    </div>

                    <div class="row">
                        <div class="col-12">
                            <p>
                            <strong>
                                Assigned Readings:
                            </strong>
                            </p>
                        </div>
                    </div>

                    <div class="row">
                        <div class="col-8">
                            <p>
                                Bolukbasi, T., Chang, K.W., Zou, J.Y., Saligrama, V. and Kalai, A.T., 2016. <a href="https://arxiv.org/abs/1607.06520" class="moreInfo">Man is to computer programmer as woman is to homemaker? Debiasing word embeddings.</a> In Advances in neural information processing systems (pp. 4349-4357).
                            </p>
                        </div>
                        <div class="col-4">
                            <p class="text-muted small">
                                This piece shows that word embedding software trained on Google News articles exhibits female/male gender stereotypes and argues that the widespread use of this software could potentially amplify whatever biases are coded in their data. It suggests a methodology for modifying embeddings in a manner that removes gender stereotypes without sacrificing the computational power of these algorithms.
                            </p>
                        </div>
                    </div>

                    <!-- Template for Assigned Readings -->
                    <div class="row" hidden>
                        <div class="col-8">
                            <p>
                            title
                            </p>
                        </div>
                        <div class="col-4">
                            <p class="text-muted small">
                            description
                            </p>
                        </div>
                    </div>

                </div>

                <!-- Content for Implementation tab -->
                <div class="tab-pane fade" id="implementation" role="tabpanel" aria-labelledby="implementation-tab">

                    <div class="row">
                        <div class="col">
                            &nbsp;
                        </div>
                    </div>

                    <div class="row">
                    <div class="col-8">
                        <p>
                        <strong>
                            Class Agenda:
                        </strong>
                        </p>
                        <ol>
                            <li>
                                Active learning exercise:  identifying analogies that reflect gender stereotypes.
                            </li>
                            <li>
                                Class discussion: what is a stereotype?
                            </li>
                            <li>
                                Presentation on the findings of gender biases in word2vec.
                            </li>
                            <li>
                                Small group discussion: what is wrong with allowing gender biases into word-embeddings?
                            </li>
                            <li>
                                Class-wide discussion about the moral issues raised by different kinds of bias.
                            </li>
                            <li>
                                Discussion of debiasing techniques and their advantages and disadvantages.
                            </li>
                        </ol>
                    </div>

                    <div class="row">
                        <div class="col">
                            <hr>
                        </div>
                    </div>

                    <div class="row">
                        <div class="col-8">
                            <p>
                            <strong>
                                Sample Class Activity:
                            </strong>
                            </p>
                            <p>
                                At the beginning of the session, students are given a list of analogies that link professions to genders, including ballerina/dancer, hostess/bartender, vocalist/guitarist, among others. They are asked to mark those analogies that reflect gender stereotypes. When they finish, the lecturer polls students to find out how they responded to four analogies: one that is clearly stereotypical (homemaker/computer scientist), one that is not (Queen/King), and two that are debatable (Diva/Rockstar, and Interior Designer/Architect). The Embedded Ethics fellow then leads a discussion about the distinctive features of gender stereotypes, which serves as a starting point to discuss the ethical problems raised by the existence gender biases in word-embeddings.
                            </p>
                        </div>
                        <div class="col-4">
                            <p class="text-muted small">
                                
                            </p>
                        </div>
                    
                    </div>

                    <div class="row">
                        <div class="col">
                            <hr>
                        </div>
                    </div>

                    <div class="row">
                        <div class="col-8">
                            <p>
                            <strong>
                                Module Assignment:
                            </strong>
                            </p>
                            <p>
                                Students are asked to imagine that they are tasked with producing an image captioning software that employs machine learning. They are directed to focus on the generation of gender-specific caption words, choosing between two models. The first model relies on learned priors based on the image context. It exploits contextual cues to determine gender-specific words. The second model generates gender-specific words based on the appearance of persons in the scene. This model incorporates an equalizer, which ensures equal gender probability when gender evidence is occluded and confident predictions when gender evidence is present. Further, it limits gender evidence to the visual aspects of persons.
                            </p>
                            <p>
                                After considering the two models, students are asked if either or both might perpetuate or amplify gender biases and, if the answer is positive, whether these models may solidify harmful stereotypes. They are then asked to consider which demographic groups might be rendered vulnerable to harmful stereotypes as a result of using the software and how such vulnerability could be prevented. 
                            </p>
                        </div>
                        <div class="col-4">
                            <p class="text-muted small">
                                
                            </p>
                    
                    </div>

                    <div class="row">
                        <div class="col">
                            <hr>
                        </div>
                    </div>

                    <div class="row">
                        <div class="col-8">
                            <p>
                            <strong>
                                Lessons Learned:
                            </strong>
                            </p>
                            <p>
                                Student response to the module was positive when it was taught in the spring of 2019. In follow-up surveys, 85.1% of students reported that they found the module interesting. 77.7% said that participating in the module helped them think more clearly about the ethical issues discussed. 85.1% said that the module increased their interest in learning about the ethical issues discussed.
                            </p>
                            <p>
                                A few things we learned from the experience:
                            </p>
                            <p>
                                The philosophical content and questions could be more strongly motivated. The module could begin with a more engaging activity so as to prevent passivity and make the ethical problem appear more urgent and engaging. Likewise, having more specific ethical questions on the table from early on could help frame and orient the exercise and encourage more in-depth philosophical discussion.
                            </p>
                            <p>
                                It would be ideal if a computer scientist could present the technical material, which is necessary for the module but requires some technical fluency to be made more interesting. 
                            </p>
                            <p>
                                Technical terms and key philosophical questions should be explained at depth, and examples of abstract ideas should be given so as to maximize clarity and improve the quality of philosophical discussion.
                            </p>
                        </div>
                    
                    </div>

                </div>

            </div>
          </div>
        </div>
      </div>
    </section>

    <div class="container">
        <div class="row">
        </div>
    </div>

    <!-- Footer -->
    <footer>
      <div class="container-fluid">
        <div class="row">
          <nav class="navbar navbar-dark bg-dark" style="width: 100%; margin-bottom: -1.75em;">
            <!-- Navbar content -->
            <div class="col-md-2 col-lg-1">
              <a class="navbar-brand" rel="license" href="http://creativecommons.org/licenses/by/4.0/" target="_blank">
                <img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" />
              </a>
            </div>
            <div class="col-md-10 col-lg-11">
              <div class="copyright mr-auto">
                <span style="color: #A6A6A6">Except where otherwise noted, content on this site is licensed under a </span>
                <a rel="license" href="http://creativecommons.org/licenses/by/4.0/" target="_blank">Creative Commons Attribution 4.0 International License</a>.
                |
                <a href="https://accessibility.huit.harvard.edu/digital-accessibility-policy">Accessibility</a>
              </div>
            </div>
          </nav>
        </div>
      </div>
    </footer>

    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

    <!-- Contact form JavaScript -->
    <script src="js/jqBootstrapValidation.js"></script>
    <script src="js/contact_me.js"></script>

    <!-- Custom scripts for this template -->
    <script src="js/agency.min.js"></script>

  </body>

</html>
