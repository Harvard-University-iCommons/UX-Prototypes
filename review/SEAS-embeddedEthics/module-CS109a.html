<!DOCTYPE html>
<html lang="en">

  <head>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-131338240-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-131338240-1');
    </script>

    <meta name="description"
          content="Embedded EthiCS @ Harvard integrates ethical reasoning into core Computer Science courses. It teaches students to think through the ethical and social implications of the systems, programs, and algorithms they design and develop.">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <!-- Favicons -->
    <link href="img/favicon.png" rel="icon">
    <link href="img/apple-touch-icon.png" rel="apple-touch-icon">

    <title>Course Modules | CS 109a | Embedded EthiCS @ Harvard</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Icon library at https://fontawesome.com/icons -->
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.2/css/all.css" integrity="sha384-/rXc/GQVaYpyDdyxK+ecHPVYJSN9bmVFBvjA/9eOB+pb3F2w2N6fc5qB9Ew5yIns" crossorigin="anonymous">

    <!-- Custom fonts for this template -->
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Kaushan+Script' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700' rel='stylesheet' type='text/css'>

    <!-- Custom styles for this template -->
    <link href="css/agency.min.css" rel="stylesheet">

    <style>
      a.moreInfo:link, a.moreInfo:visited {
          color: #AB4E03;
          text-decoration: none;
          background-color: transparent;
          -webkit-text-decoration-skip: objects;
          font-size: 1.05em;
      }

      section h3.section-subheading {
      font-size: 1.5em;
      font-weight: 400;
      font-style: normal;
      margin-bottom: 75px;
      text-transform: none;
      font-family: arial;
      }

      .copyright {
      color: #999;
      }

      .navbar-nav {
      font-family: Montserrat,-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,'Helvetica Neue',Arial,sans-serif,'Apple Color Emoji','Segoe UI Emoji','Segoe UI Symbol','Noto Color Emoji';
      font-size: 90%;
      font-weight: 400;
      }

      .navbar-dark .navbar-nav .nav-link {
      color: #fff;
      }

      a.nav-link {
      color: #fff;
      padding: 1.1em 1em!important;
      }

    </style>

  </head>

  <body id="page-top">

    <!-- Navbar -->
    <nav class="navbar fixed-top navbar-expand-lg navbar-dark bg-dark">

      <a class="navbar-brand">
        <img src="img/harvard-logo.png" alt="Harvard University logo" width="200">
      </a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>

      <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav ml-auto text-uppercase">
          <li class="nav-item">
            <a class="nav-link" href="index.html">Home</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="about.html">About</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="team.html">Team</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="module.html" style="color: #fed136;">Course Modules</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="news.html">
              News
            </a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="publications.html">Publications</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="contact.html">Contact us</a>
          </li>
        </ul>
      </div>

    </nav>

    <h1 hidden>
      Embedded ethics at Harvard: Harvard: bringing ethical reasoning into the computer science curriculum.
    </h1>

    <!-- Header -->
    <header class="masthead">
      <div class="container">
        <div class="row">
          <div class="col-md-12">
            <div style=" margin-top: 6em; padding: 1em; background: none repeat scroll 0 0 rgba(108, 109, 110, 0);">
              <div class="intro-lead-in" style="line-height: 1.5em; font-family:verdana,arial,sans-serif; font-style: normal; color: #fff; font-size: 1.3em;">
                <span style="color: #FFDB6D; font-weight: 400;">
                  Embedded EthiCS
                </span>
                <span style="font-size: smaller;">@</span>
                Harvard: bringing ethical reasoning into the computer science curriculum.
              </div>
            </div>
          </div>
        </div>
      </div>
    </header>

    <div class="container" style="margin-top: 2em;">
        <div class="row">
          <div class="col-md-12">
            <a href="module.html" class="moreInfo">Course Modules</a>
            / CS 109a: Introduction to Data Science 
          </div>
        </div>
    </div>

    <section id="module">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center" style="margin-top: -5em;">
            <h2 class="section-heading" style="font-size: 2em;">Repository of Open Source Course Modules</h2>
          </div>
        </div>

        <div class="row" style="margin-top: 4em;">
          <div class="col-md-12">
            <!-- Tabs -->
            <ul class="nav nav-tabs justify-content-center" id="myTab" role="tablist">
              <li class="nav-item">
                <a class="nav-link active moreInfo" id="home-tab" data-toggle="tab" href="#overview" role="tab" aria-controls="home" aria-selected="true">
                  Overview
                </a>
              </li>
              <li class="nav-item">
                <a class="nav-link moreInfo" id="goal-tab" data-toggle="tab" href="#goal" role="tab" aria-controls="goal" aria-selected="false">
                  Goals
                </a>
              </li>
              <li class="nav-item">
                <a class="nav-link moreInfo" id="material-tab" data-toggle="tab" href="#material" role="tab" aria-controls="material" aria-selected="false">
                  Materials
                </a>
              </li>
              <li class="nav-item">
                <a class="nav-link moreInfo" id="implementation-tab" data-toggle="tab" href="#implementation" role="tab" aria-controls="implementation" aria-selected="false">
                  Implementation
                </a>
              </li>
            </ul>
            <div class="tab-content" id="myTabContent">

                <!-- Content for Overview tab -->
                <div class="tab-pane fade show active" id="overview" role="tabpanel" aria-labelledby="home-tab">

                    <div class="row">
                        <div class="col">
                            &nbsp;
                        </div>
                        </div>

                        <div class="row">
                        <div class="col-8">
                            <p>
                            <strong>
                                Course:
                            </strong>
                            CS 109a: Introduction to Data Science
                            </p>
                            <p>
                            <strong>
                                Course Level:
                            </strong>
                            Upper-level undergraduate
                            </p>
                            <p>
                            <strong>
                                Course Description:
                            </strong>
                            “This course is the first half of a one‐year introduction to data science. We will focus on the analysis of data to perform predictions using statistical and machine learning methods. Topics include data scraping, data management, data visualization, regression and classification methods, and deep neural networks. You will get ample practice through weekly homework assignments. The class material integrates the five key facets of an investigation using data:
                            </p>
                            <ol>
                                <li>
                                    data collection ‐ data wrangling, cleaning, and sampling to get a suitable data set
                                </li>
                                <li>
                                    data management ‐ accessing data quickly and reliably
                                </li>
                                <li>
                                    exploratory data analysis – generating hypotheses and building intuition
                                </li>
                                <li>
                                    prediction or statistical learning
                                </li>
                                <li>
                                    communication – summarizing results through visualization, stories, and interpretable summaries
                                </li>
                            </ol>

                            (<a href="https://harvard-iacs.github.io/2019-CS109A/" target="_blank" class="moreInfo">Course description
                                <sup><i class="fas fa-external-link-alt fa-sm"></i></sup></a>)"
                            </p>
                        </div>
                        <div class="col-4">
                        </div>
                    </div>

                    <div class="row">
                        <div class="col">
                            <hr>
                        </div>
                    </div>

                    <div class="row">
                        <div class="col-8">
                            <p>
                            <strong>
                                Module Topic:
                            </strong>
                            Algorithmic Fairness and Recidivism Prediction
                            </p>
                            <p>
                            <strong>
                                Module Author:
                            </strong>
                            Heather Spradley
                            </p>
                            <p>
                            <strong>
                                Semesters Taught:
                            </strong>
                            Spring 2020
                            </p>
                            <p>
                            <strong>
                                Tags:
                            </strong>
                            </p>
                            <dl>
                                <dd>
                                    fairness <span class="badge badge-warning">phil</span>
                                </dd>
                                <dd>
                                    discrimination <span class="badge badge-warning">phil</span>
                                </dd>
                                <dd>
                                    prediction <span class="badge badge-primary">CS</span>
                                </dd>
                                <dd>
                                    machine learning <span class="badge badge-primary">CS</span>
                                </dd>
                                <dd>
                                    bias <span class="badge badge-success">both</span>
                                </dd>
                            </dl>
                            <p>
                            <strong>
                                Module Overview:
                            </strong>
                            </p>
                            <p>
                                In this module, we discuss algorithmic fairness, focusing on the special case of fairness in recidivism prediction. The central case study for the module is COMPAS, a recidivism prediction tool that is used widely in the criminal justice system. In 2016, ProPublica published a piece arguing that COMPAS is unfairly biased against black defendants on the grounds that the tool’s false positive rate for black defendants is higher than its false positive rate for white defendants. Northpointe, the company that developed COMPAS, responded by arguing that the tool is “racially neutral” because it is calibrated between races: any two individuals that receive the same score are equally likely to reoffend, regardless of race. After reconstructing and evaluating both arguments (and drawing on John Rawls’ views about procedural fairness in A Theory of Justice), we consider more general questions about fairness in recidivism prediction. How, in general, might preexisting racial bias affect the performance of recidivism prediction tools based on machine learning? What can data scientists working on recidivism prediction problems do to help ensure that the systems they develop are fair? And should the criminal justice system be using recidivism prediction algorithms to make decisions in the first place?
                            </p>
                        </div>
                        <div class="col-4">
                        </div>
                    </div>

                    <div class="row">
                        <div class="col">
                            <hr>
                        </div>
                    </div>

                    <div class="row">
                        <div class="col-8">
                            <p>
                            <strong>
                                Connection to Course Material:
                            </strong>
                            In this course, students learn how to build predictive models and consider various problems that interfere with the accuracy of these models, such as feedback loops. In the module, we consider how to develop predictive models that are both accurate and fair. We also challenge the idea that ensuring fairness requires sacrificing accuracy, particularly in the case of recidivism prediction. 
                            </p>
                        </div>
                        <div class="col-4">
                            <p class="text-muted small">
                            
                            </p>
                        </div>
                    </div>

                </div>

                <!-- Content for Goals tab -->
                <div class="tab-pane fade" id="goal" role="tabpanel" aria-labelledby="goal-tab">

                    <div class="row">
                    <div class="col">
                        &nbsp;
                    </div>
                    </div>

                    <div class="row">
                        <div class="col-8">
                            <p>
                            <strong>
                                Module Goals:
                            </strong>
                            </p>
                            <ol>
                                <li>
                                    Introduce students to the topic of algorithmic fairness, with a focus on fairness in recidivism prediction.
                                </li>
                                <li>
                                    Consider various ways in which predictive algorithms might be unfair, as well as how to develop fairer predictive algorithms. 
                                </li>
                                <li>
                                    Equip students with philosophical tools to help them think more clearly about algorithmic fairness.
                                </li>
                            </ol>
                        </div>
                        <div class="col-4"></div>
                    </div>

                    <div class="row">
                    <div class="col">
                        <hr>
                    </div>
                    </div>

                    <div class="row">
                    <div class="col-8">
                        <p>
                        <strong>
                            Key Philosophical Questions:
                        </strong>
                        </p>
                        <ol>
                            <li>
                                What is fairness and what features of a predictive algorithm make it fair?
                            </li>
                            <li>
                                What kinds of features of an individual would a fair algorithm take into account?
                            </li>
                            <li>
                                In what ways can data collection be done fairly or unfairly and how does that impact the fairness of the predictive model that was trained on that data?
                            </li>
                        </ol>
                    </div>
                    <div class="col-4">
                        <p class="text-muted small">

                        </p>
                    </div>
                    </div>

                </div>

                <!-- Content for Material tab -->
                <div class="tab-pane fade" id="material" role="tabpanel" aria-labelledby="material-tab">

                    <div class="row">
                    <div class="col">
                        &nbsp;
                    </div>
                    </div>

                    <div class="row">
                        <div class="col-8">
                            <p>
                            <strong>
                                Key Philosophical Concepts:
                            </strong>
                            </p>
                            <ul>
                                <li>
                                    Fairness
                                </li>
                                <li>
                                    John Rawls’ “veil of ignorance” thought experiment
                                </li>
                                <li>
                                    Moral relevance and irrelevance
                                </li>
                                <li>
                                    Bias
                                </li>
                                <li>
                                    Discrimination
                                </li>
                            </ul>
                        </div>
                        <div class="col-4">
                            <p class="text-muted small">

                            </p>
                        </div>
                    </div>

                    <div class="row">
                        <div class="col-12">
                            <p>
                            <strong>
                                Assigned Readings:
                            </strong>
                            </p>
                        </div>
                    </div>

                    <div class="row">
                        <div class="col-8">
                            <p>
                                Julia Angwin, Jeff Larson, Surya Mattu and Lauren Kirchner, “Machine Bias” (ProPublica).
                            </p>
                        </div>
                        <div class="col-4">
                            <p class="text-muted small">
                                This piece by ProPublica initiated the debate about whether COMPAS is biased against black defendants. In addition to introducing students to one of the central arguments in that debate, the reading provides useful background about COMPAS and how it is used in the criminal justice system.
                                <br>
                                One of the main reasons for choosing this topic was the extent to which it has been discussed and addressed in the CS community. Although it is often helpful to draw students’ attention brand new issues they might not have noticed before, we had a unique opportunity here to address something that already felt pressing to students and to give them philosophical tools to navigate the ongoing discussion in the CS community. Since this is the article that drew so much attention to the topic, it served as a great starting point for walking students through the current discussion in their community while also introducing them to philosophical tools for reflecting on the concepts such as “fairness” and “bias”. 
                            </p>
                        </div>
                    </div>

                    <!-- Template for Assigned Readings -->
                    <div class="row" hidden>
                        <div class="col-8">
                            <p>
                            title
                            </p>
                        </div>
                        <div class="col-4">
                            <p class="text-muted small">
                            description
                            </p>
                        </div>
                    </div>

                </div>

                <!-- Content for Implementation tab -->
                <div class="tab-pane fade" id="implementation" role="tabpanel" aria-labelledby="implementation-tab">

                    <div class="row">
                        <div class="col">
                            &nbsp;
                        </div>
                    </div>

                    <div class="row">
                    <div class="col-12">
                        <p>
                        <strong>
                            Class Agenda:
                        </strong>
                        </p>
                        <ol>
                        <li>
                            Overview.
                        </li>
                        <li>
                            Case study: the COMPAS recidivism prediction tool.
                        </li>
                        <li>
                            ProPublica’s argument that COMPAS is unfair.
                        </li>
                        <li>
                            Philosophical concepts: fairness, moral relevance, John Rawls’ veil of ignorance thought experiment.
                        </li>
                        <li>
                            Technical concepts: false positive rates and calibration.
                        </li>
                        <li>
                            Argument that COMPAS is fair (based on Rob Long’s article “Fairness in Machine Learning”).
                        </li>
                        <li>
                            Data and data collection as further objections to the fairness of COMPAS.
                        </li>
                        <li>
                            Discussion.
                        </li>
                        </ol>
                    </div>

                    <div class="row">
                        <div class="col">
                            <hr>
                        </div>
                    </div>

                    <div class="row">
                        <div class="col-8">
                            <p>
                            <strong>
                                Sample Class Activity:
                            </strong>
                            </p>
                            <p>
                                In order to get students to feel the force of the ethical questions about predictive algorithms used in recidivism prediction, the module begins with two polls. In the first poll, students are asked to consider a scenario in which they are a judge making a pre-trial decision: they must decide whether to make that decision based on their own judgment or based on a risk assessment produced by a predictive algorithm. In the second poll, they are asked to make the same decision but from the perspective of the detainee about whom the pre-trial decision is being made. After the polls are complete, the students discuss their reasons for their answers. Then, they are asked to consider the common assumption that predictive tools will allow us to pass the buck on certain kinds of responsibilities in high stakes cases. They then discuss the way in which the responsibility of the creator of the predictive algorithm is heightened because of the way in which the algorithms are relied upon. This module was prepared for a very large class, so part of the motivation behind this assignment was that it could be done with several hundred people. In smaller classes, longer or more complicated activities would be possible. Taking polls worked well in that students were able to respond simultaneously and the results brought out interesting discussion.
                            </p>
                        </div>
                    
                    </div>

                    <div class="row">
                        <div class="col">
                            <hr>
                        </div>
                    </div>

                    <div class="row">
                        <div class="col-8">
                            <p>
                            <strong>
                                Module Assignment:
                            </strong>
                            </p>
                            <p>
                                In a post-module assignment, students are asked to explore recidivism data and corresponding COMPAS scores published by ProPublica. They are then asked to: (1) find correlations and differences between a defendant’s race and various other variables in the data; (2) write a short response to the question, “With respect to these variables, how could bias in the data or data collection be impacting or causing these differences?”; (3) build three predictive models from the data that leave out race and other correlating variables in different ways in order to see what impact different variables are having on the model; and (4) discuss the resulting false positive rates amongst different racial groups in each of their models and what implications this has for the fairness of predictive algorithms.
                                One motivation behind this assignment was to get students to see just how different the results of various models can be depending on decisions made with respect to the fairness of the data. Many students tend to think of the task as one of representing data as accurately as possible in a model, but this exercise forces them to challenge that idea. They are able to think through in practice the relation between accuracy and fairness by building and running several models.
                            </p>
                        </div>
                    
                    </div>

                    <div class="row">
                        <div class="col">
                            <hr>
                        </div>
                    </div>

                    <div class="row">
                        <div class="col-8">
                            <p>
                            <strong>
                                Lessons Learned:
                            </strong>
                            </p>
                            <p>
                                Since the course had recently covered the technical concepts of calibration and false positive rates, we assumed that spending time reviewing these concepts would be unnecessary. In practice, however, we found that some students were not fluent enough with these concepts to readily apply them in the context of a new discussion about algorithmic fairness. When we teach the module again, we plan to spend more time reviewing these concepts before introducing new material.
                            </p>
                        </div>
                    
                    </div>

                </div>

            </div>
          </div>
        </div>
      </div>
    </section>

    <div class="container">
      <div class="row">
      </div>
    </div>

    <!-- Footer -->
    <footer>
      <div class="container-fluid">
        <div class="row">
          <nav class="navbar navbar-dark bg-dark" style="width: 100%; margin-bottom: -1.75em;">
            <!-- Navbar content -->
            <div class="col-md-2 col-lg-1">
              <a class="navbar-brand" rel="license" href="http://creativecommons.org/licenses/by/4.0/" target="_blank">
                <img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" />
              </a>
            </div>
            <div class="col-md-10 col-lg-11">
              <div class="copyright mr-auto">
                <span style="color: #A6A6A6">Except where otherwise noted, content on this site is licensed under a </span>
                <a rel="license" href="http://creativecommons.org/licenses/by/4.0/" target="_blank">Creative Commons Attribution 4.0 International License</a>.
                |
                <a href="https://accessibility.huit.harvard.edu/digital-accessibility-policy">Accessibility</a>
              </div>
            </div>
          </nav>
        </div>
      </div>
    </footer>

    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

    <!-- Contact form JavaScript -->
    <script src="js/jqBootstrapValidation.js"></script>
    <script src="js/contact_me.js"></script>

    <!-- Custom scripts for this template -->
    <script src="js/agency.min.js"></script>

  </body>

</html>
